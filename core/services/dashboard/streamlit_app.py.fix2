import logging
import os

import pandas as pd
import requests
import streamlit as st

# ============================================================================
# ENVIRONMENT-AWARE CONFIGURATION
# ============================================================================
# Service URLs - automatically adapt to local Docker or GCP deployment
ENVIRONMENT = os.getenv("ENVIRONMENT", "dev")
VERTICAL = os.getenv("VERTICAL", "supply-chain")

KAFKA_BOOTSTRAP_SERVERS = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "kafka:9092")
MLFLOW_TRACKING_URI = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")
MODEL_INFERENCE_URL = os.getenv("MODEL_INFERENCE_URL", "http://model-inference:8001")
RAG_SERVICE_URL = os.getenv("RAG_SERVICE_URL", "http://rag-service:8005")
PROMETHEUS_URL = os.getenv("PROMETHEUS_URL", "http://prometheus:9090")

# MLflow UI URL for browser (localhost for dev, tracking URI for production)
MLFLOW_UI_URL = "http://localhost:5001" if ENVIRONMENT == "dev" else MLFLOW_TRACKING_URI


# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Page config
st.set_page_config(
    page_title="AI Platform Dashboard",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS - Complete white theme with black text
st.markdown(
    """
<style>
    /* === GLOBAL WHITE THEME ============================================= */

    /* Main content & sidebar */
    .main,
    [data-testid="stSidebar"],
    [data-testid="stSidebar"] > div:first-child,
    header[data-testid="stHeader"],
    .css-18ni7ap, .css-vfskoc {
        background-color: #ffffff !important;
    }

    /* Universal text color */
    body, p, span, div, h1, h2, h3, h4, h5, h6, label {
        color: #000000 !important;
    }

    /* Metrics */
    [data-testid="stMetricLabel"], [data-testid="stMetricValue"] {
        color: #000000 !important;
    }
    [data-testid="stMetric"] {
        background-color: #f8f9fa !important;
        padding: 15px;
        border-radius: 10px;
        border: 1px solid #e9ecef;
    }

    /* === FORMS & CONTROLS =============================================== */

    /* Radio buttons */
    div[role="radiogroup"] label {
        color: #000000 !important;
        cursor: pointer !important;
        padding: 8px 12px !important;
        border-radius: 6px !important;
        transition: all 0.2s ease !important;
    }
    div[role="radiogroup"] label:hover {
        background-color: #f8f9fa !important;
    }
    div[role="radiogroup"] label > div:first-child {
        border: 2px solid #495057 !important;
        background-color: white !important;
        width: 18px !important;
        height: 18px !important;
    }
    div[role="radiogroup"] input[type="radio"]:checked ~ div:first-child {
        background-color: #0d6efd !important;
        border-color: #0d6efd !important;
        box-shadow: 0 0 0 3px rgba(13, 110, 253, 0.15) !important;
    }
    div[role="radiogroup"] input[type="radio"]:checked ~ div {
        font-weight: 600 !important;
        color: #0d6efd !important;
    }

    /* Buttons */
    .stButton button,
    [data-testid="stLinkButton"] button,
    .stButton a {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: 1px solid #e9ecef !important;
    }
    .stButton button:hover,
    [data-testid="stLinkButton"] button:hover,
    .stButton a:hover {
        background-color: #f8f9fa !important;
        border: 1px solid #dee2e6 !important;
    }
    .stButton button[kind="primary"],
    .stFormSubmitButton button {
        background-color: #0d6efd !important;
        color: #ffffff !important;
        border: none !important;
    }

    /* Number inputs */
    .stNumberInput input {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: 1px solid #e9ecef !important;
    }
    [data-testid="stNumberInput"] button {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: 1px solid #ced4da !important;
        box-shadow: none !important;
    }
    [data-testid="stNumberInput"] button:hover {
        background-color: #f8f9fa !important;
        border-color: #adb5bd !important;
    }

    /* Text & select inputs */
    .stTextInput input,
    .stSelectbox select {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: 1px solid #e9ecef !important;
    }
    div[data-baseweb="select"] > div,
    [role="listbox"], [role="option"] {
        background-color: #ffffff !important;
        color: #000000 !important;
    }
    [role="option"]:hover {
        background-color: #f8f9fa !important;
    }

    /* Slider labels */
    .stSlider label { color: #000000 !important; }

    /* === CONTAINERS / EXPANDERS ======================================== */

    [data-testid="stExpander"],
    [data-testid="stExpanderHeader"],
    [data-testid="stExpander"] > div:first-child,
    [data-testid="stExpander"] [data-testid="stMarkdownContainer"],
    [data-testid="stExpander"] div[data-testid="stVerticalBlock"] {
        background-color: #ffffff !important;
        color: #000000 !important;
    }
    [data-testid="stExpander"] {
        border: 1px solid #dee2e6 !important;
        border-radius: 6px !important;
    }
    [data-testid="stExpanderHeader"] {
        background-color: #f8f9fa !important;
        font-weight: 600 !important;
    }

    /* === JSON VIEWER ==================================================== */

    [data-testid="stJson"],
    [data-testid="stJson"] > div,
    [data-testid="stJson"] pre,
    [data-testid="stJson"] span,
    [data-testid="stJson"] .string,
    [data-testid="stJson"] .number,
    [data-testid="stJson"] .key {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: none !important;
    }
    [data-testid="stJson"] {
        border: 1px solid #dee2e6 !important;
        border-radius: 6px !important;
        padding: 1rem !important;
    }

    /* === TABLES / DATAFRAMES =========================================== */

    [data-testid="stDataFrame"] div[data-testid="stTableContainer"] {
        background-color: #ffffff !important;
        color: #000000 !important;
        border-radius: 8px !important;
        border: 1px solid #dee2e6 !important;
    }
    [data-testid="stDataFrame"] thead tr th {
        background-color: #f8f9fa !important;
        color: #000000 !important;
        border-bottom: 2px solid #dee2e6 !important;
        font-weight: 600 !important;
    }
    [data-testid="stDataFrame"] tbody tr td {
        background-color: #ffffff !important;
        color: #000000 !important;
        border-bottom: 1px solid #dee2e6 !important;
    }
    [data-testid="stDataFrame"] tbody tr:hover td {
        background-color: #f1f3f5 !important;
    }
    [data-testid="stDataFrame"]::-webkit-scrollbar {
        height: 10px;
    }
    [data-testid="stDataFrame"]::-webkit-scrollbar-thumb {
        background-color: #adb5bd;
        border-radius: 6px;
    }

    /* === MISC ELEMENTS ================================================== */

    hr { border-color: #e9ecef !important; }

    code, pre code {
        background-color: #f8f9fa !important;
        color: #212529 !important;
        padding: 2px 6px !important;
        border-radius: 3px !important;
    }

    /* Captions, divs */
    [data-testid="stCaptionContainer"], .element-container {
        color: #495057 !important;
    }

    /* Success & warning boxes */
    .success-box {
        background-color: #d4edda !important;
        border-left: 4px solid #28a745;
        border-radius: 5px;
        padding: 10px;
        color: #155724 !important;
    }
    .warning-box {
        background-color: #fff3cd !important;
        border-left: 4px solid #ffc107;
        border-radius: 5px;
        padding: 10px;
        color: #856404 !important;
    }

    /* ==== DataFrame hard reset (table + toolbar) ==== */
    [data-testid="stDataFrame"] * {
        background-color: #ffffff !important;
        color: #000000 !important;
    }

    [data-testid="stDataFrame"] thead th {
        background-color: #f8f9fa !important;
        color: #000000 !important;
        border-bottom: 2px solid #dee2e6 !important;
        font-weight: 600 !important;
    }

    [data-testid="stDataFrame"] tbody td {
        border-bottom: 1px solid #dee2e6 !important;
    }

    [data-testid="stDataFrame"] tbody tr:hover td {
        background-color: #f1f3f5 !important;
    }

    /* toolbar (download/search/fullscreen) */
    [data-testid="stDataFrame"] [data-testid="stElementToolbar"],
    [data-testid="stDataFrame"] [data-testid="stElementToolbar"] * {
        background-color: #ffffff !important;
        color: #000000 !important;
        border-color: #e9ecef !important;
    }

    /* ==== Link buttons (st.link_button) ==== */
    [data-testid="stLinkButton"],
    [data-testid="stLinkButton"] > a,
    [data-testid="stLinkButton"] > a > div {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: 1px solid #e9ecef !important;
        border-radius: 12px !important;
        box-shadow: none !important;
    }

    [data-testid="stLinkButton"]:hover,
    [data-testid="stLinkButton"] > a:hover,
    [data-testid="stLinkButton"] > a > div:hover {
        background-color: #f8f9fa !important;
        color: #000000 !important;
        border-color: #dee2e6 !important;
    }

    /* ==== Restore text visibility inside DataFrame cells ==== */
    [data-testid="stDataFrame"] span,
    [data-testid="stDataFrame"] div,
    [data-testid="stDataFrame"] p {
        color: #000000 !important;
        background-color: transparent !important;
        opacity: 1 !important;
    }

    /* make sure numeric and text content in cells stay black */
    [data-testid="stDataFrame"] .cell,
    [data-testid="stDataFrame"] .row_heading,
    [data-testid="stDataFrame"] .col_heading {
        color: #000000 !important;
    }

    /* fix hover overlay transparency */
    [data-testid="stDataFrame"] tbody tr:hover {
        background-color: #f8f9fa !important;
    }

    /* just to be safe: reset SVG (icons like checkmarks) to visible */
    [data-testid="stDataFrame"] svg {
        fill: #000000 !important;
        color: #000000 !important;
    }

</style>
""",
    unsafe_allow_html=True,
)


# Configuration
MLFLOW_TRACKING_URI = MLFLOW_TRACKING_URI
RAG_URL = "https://rag-service-742330383495.us-central1.run.app"
AI_GATEWAY_URL = "https://ai-gateway-dakmfhg3aa-uc.a.run.app"
MODEL_INFERENCE_URL = MODEL_INFERENCE_URL
# METRICS_API_URL = PROMETHEUS_URL
METRICS_API_URL = os.getenv(
    "ML_CONSUMER_METRICS_URL", PROMETHEUS_URL
).replace("/metrics", "")


def get_kafka_metrics():
    """Get Kafka metrics from ML Consumer API"""
    try:
        response = requests.get(f"{METRICS_API_URL}/metrics/kafka", timeout=5)

        if response.status_code == 200:
            logger.info("‚úÖ Got real Kafka metrics from ml-consumer")
            data = response.json()

            # Filter out internal topics (starting with _)
            if "topics" in data:
                data["topics"] = [
                    t for t in data["topics"] if not t.get("name", "").startswith("_")
                ]

            return data
        else:
            logger.warning(f"Metrics API returned {response.status_code}")
            return get_mock_kafka_metrics()

    except requests.Timeout:
        logger.warning("Metrics API timeout - using mock data")
        return get_mock_kafka_metrics()
    except Exception as e:
        logger.error(f"Error fetching Kafka metrics: {e}")
        return get_mock_kafka_metrics()


def get_redis_metrics():
    """Get Redis metrics - Currently not deployed"""
    try:
        response = requests.get(f"{METRICS_API_URL}/metrics/redis", timeout=5)

        if response.status_code == 200:
            data = response.json()
            if data.get("status") == "not_deployed":
                return get_redis_not_deployed_message()
            return data
        else:
            return get_redis_not_deployed_message()
    except Exception:
        return get_redis_not_deployed_message()


def get_consumer_metrics():
    """Get ML Consumer processing statistics"""
    try:
        response = requests.get(f"{METRICS_API_URL}/metrics/consumer", timeout=5)

        if response.status_code == 200:
            return response.json()
        return None
    except Exception:
        return None


def check_metrics_api_health():
    """Check if Metrics API is available"""
    try:
        response = requests.get(f"{METRICS_API_URL}/health", timeout=3)
        if response.status_code == 200:
            return True, response.json()
        return False, None
    except Exception:
        return False, None


def show_metrics_api_status():
    """Show Metrics API connection status"""
    is_live, health_data = check_metrics_api_health()

    if is_live:
        messages_processed = health_data.get("messages_processed", 0)
        consumer_active = health_data.get("consumer_active", False)

        st.markdown(
            f'<div class="success-box">'
            f"üü¢ Connected to ML Consumer Metrics API (GKE)<br>"
            f'<strong>Status:</strong> Consumer {"Active" if consumer_active else "Inactive"} | '  # noqa: E501
            f"<strong>Messages Processed:</strong> {messages_processed:,}"
            f"</div>",
            unsafe_allow_html=True,
        )
        return True
    else:
        st.markdown(
            '<div class="warning-box">'
            "‚ö†Ô∏è Metrics API unavailable - Using fallback data."
            "</div>",
            unsafe_allow_html=True,
        )
        return False


# Fallback mock data
def get_mock_kafka_metrics():
    """Fallback when API unavailable - shows actual topic structure"""
    return {
        "topics": [
            {
                "name": "supply-chain.orders",
                "partitions": 3,
                "replication": 1,
                "messages_per_sec": 0.0,
                "lag": 0,
            },
            {
                "name": "supply-chain.predictions",
                "partitions": 3,
                "replication": 1,
                "messages_per_sec": 0.0,
                "lag": 0,
            },
            {
                "name": "supply-chain.alerts",
                "partitions": 3,
                "replication": 1,
                "messages_per_sec": 0.0,
                "lag": 0,
            },
            {
                "name": "supply-chain.dead-letter",
                "partitions": 1,
                "replication": 1,
                "messages_per_sec": 0.0,
                "lag": 0,
            },
        ],
        "consumer_groups": [
            {
                "group_id": "ml-consumer-group",
                "state": "Stable",
                "members": 1,
                "lag": 0,
                "topics": ["supply-chain.orders"],
            }
        ],
        "brokers": {"count": 1, "status": "unknown"},
        "total_throughput": 0.0,
        "total_lag": 0,
    }


def get_redis_not_deployed_message():
    """Redis not deployed message"""
    return {
        "status": "not_deployed",
        "message": "Redis/Memorystore exists in Terraform but not yet integrated",  # noqa: E501
    }


# Sidebar
with st.sidebar:
    st.title("üöÄ AI Platform")
    st.markdown("---")

    page = st.radio(
        "Navigation",
        [
            "üè† Overview",
            "üìä Live Pipeline",
            "üß™ MLflow",
            "ü§ñ RAG",
            "üß† ML Models",
            "‚ù§Ô∏è Health",
        ],
        label_visibility="collapsed",
    )

    st.markdown("---")
    st.markdown("### Quick Stats")
    st.metric("Orders", "42+", "+3")
    st.metric("Success", "100%")
    st.metric("Latency", "0.8ms")

    st.markdown("---")
    st.caption("**Built in:** 4 days")
    st.caption("**Cost:** $85-150/mo")
    st.caption("**Status:** üü¢ Live")

# Main content
if page == "üè† Overview":
    st.title("üéâ AI Platform Dashboard")
    st.markdown("### Production-Ready ML Pipeline & Intelligence System")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Orders Processed", "42", "+3 today")
    with col2:
        st.metric("Success Rate", "100%", "Perfect")
    with col3:
        st.metric("Avg Latency", "0.8ms", "‚Üì 0.2ms")
    with col4:
        st.metric("Alerts", "4", "+1")

    st.markdown("---")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### üèóÔ∏è Architecture")
        st.markdown(
            """
        - **Event-Driven ML** with Kafka on GKE
        - **MLflow Tracking** with PostgreSQL
        - **Custom ML Models** (scikit-learn, PyTorch)
        - **RAG System** with Vertex AI + Pinecone
        - **AI Gateway** (Claude/GPT-4/Gemini)
        - **VPC Peering** for connectivity
        - **100% IaC** with Terraform
        """
        )

        st.markdown("### üìà Achievements")
        st.markdown(
            """
        - ‚úÖ Zero failures (40+ orders)
        - ‚úÖ Sub-millisecond latency
        - ‚úÖ Custom ML models (85% R¬≤ accuracy)
        - ‚úÖ Production patterns (DLQ, retry)
        - ‚úÖ Cost-optimized ($85-150/mo)
        - ‚úÖ Built in 4 days, zero GCP experience
        """
        )

    with col2:
        st.markdown("### üéØ Recent Activity")

        recent_orders = pd.DataFrame(
            {
                "Order ID": [f"ORD-{i}" for i in range(8341, 8346)],
                "Product": [
                    "Widget A",
                    "Component B",
                    "Material C",
                    "Widget A",
                    "Component B",
                ],
                "Risk Score": [45.2, 78.9, 32.1, 65.4, 41.8],
                "Status": ["‚úÖ Success"] * 5,
                "Time": ["12:34:21", "12:34:18", "12:34:15", "12:34:12", "12:34:09"],
            }
        )

        st.dataframe(recent_orders, use_container_width=True, hide_index=True)

        st.markdown("### üîó Quick Links")
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.link_button("Open MLflow Dashboard", MLFLOW_UI_URL), use_container_width=True)
        with col_b:
            st.link_button(
                "üö™ Gateway", AI_GATEWAY_UI_URL + "/health", use_container_width=True
            )
        with col_c:
            st.link_button(
                "üß† ML Models", MODEL_INFERENCE_UI_URL, use_container_width=True
            )

elif page == "üìä Live Pipeline":
    st.title("üìä Live ML Pipeline")
    st.markdown("Real-time order processing with Kafka")

    # Show connection status
    is_live = show_metrics_api_status()

    # Top metrics
    col1, col2, col3, col4 = st.columns(4)

    # Get consumer stats if available
    consumer_stats = get_consumer_metrics() if is_live else None
    messages_processed = (
        consumer_stats.get("messages_processed", 0) if consumer_stats else 0
    )

    with col1:
        st.metric("Messages Processed", f"{messages_processed:,}")
    with col2:
        st.metric("Processing", "0.8ms", "‚Üì 0.2")
    with col3:
        st.metric("Queue", "0", "Empty")
    with col4:
        st.metric("DLQ", "0", "Perfect")

    st.markdown("---")

    # Kafka Section
    st.markdown("### üì® Kafka Topics & Consumer Groups")

    kafka_metrics = get_kafka_metrics()

    if kafka_metrics:
        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("#### Active Topics")
            topics_df = pd.DataFrame(kafka_metrics["topics"])
            topics_df = topics_df.rename(
                columns={
                    "name": "Topic",
                    "partitions": "Partitions",
                    "replication": "Replication",
                    "messages_per_sec": "Msgs/sec",
                    "lag": "Lag",
                }
            )
            st.dataframe(topics_df, use_container_width=True, hide_index=True)

            if is_live:
                st.caption("‚úÖ Real-time data from ml-consumer in GKE")
            else:
                st.caption("üí° Fallback data - Metrics API not reachable")

        with col2:
            st.markdown("#### Kafka Cluster")
            st.metric("Brokers", kafka_metrics["brokers"]["count"])
            st.metric(
                "Total Throughput", f"{kafka_metrics['total_throughput']:.1f}/s"
            )  # noqa: E501
            st.metric("Total Lag", kafka_metrics["total_lag"])

    st.markdown("---")

    # Redis Section
    st.markdown("### üî¥ Redis Cache")

    redis_metrics = get_redis_metrics()

    if redis_metrics.get("status") == "not_deployed":
        st.info(
            "‚ÑπÔ∏è Redis/Memorystore is provisioned in Terraform but not yet integrated with ml-consumer. "  # noqa: E501
            "Requires Serverless VPC Access or VPC connector configuration."  # noqa: E501
        )

    st.markdown("---")
    st.markdown("### üîÑ Recent Predictions")

    orders_data = pd.DataFrame(
        {
            "Order ID": [f"ORD-{8340+i}" for i in range(10)],
            "Product": ["Widget A", "Component B", "Material C"] * 3 + ["Widget A"],
            "Risk Score": [45.2, 78.9, 32.1, 65.4, 41.8, 89.2, 28.5, 55.7, 71.3, 38.9],
            "On-Time %": [87.3, 62.1, 92.5, 75.8, 88.4, 58.2, 94.1, 79.6, 67.4, 90.2],
            "Status": ["‚úÖ"] * 10,
        }
    )

    st.dataframe(orders_data, use_container_width=True, hide_index=True)

elif page == "ü§ñ RAG":
    st.title("ü§ñ RAG Intelligence")
    st.markdown("Semantic search with Vertex AI + Pinecone")

    # Initialize session state for question
    if "question" not in st.session_state:
        st.session_state.question = ""

    question = st.text_input(
        "Ask a question about supply chain",
        value=st.session_state.question,
        placeholder="e.g., What are the cold chain requirements?",
    )

    if st.button("üîç Query", type="primary", use_container_width=True):
        if question:
            with st.spinner("Searching..."):
                try:
                    response = requests.post(
                        f"{RAG_URL}/query",
                        json={"question": question, "top_k": 3},
                        timeout=120,
                    )

                    if response.status_code == 200:
                        data = response.json()

                        st.markdown("### ‚úÖ Answer")
                        answer = data.get("answer", "No answer")
                        st.markdown(
                            f'<div class="success-box">{answer}</div>',
                            unsafe_allow_html=True,
                        )

                        st.markdown("### üìö Sources")
                        sources = data.get("sources", [])
                        for i, src in enumerate(sources):
                            score = src.get("score", 0)
                            text = src.get("text", "N/A")
                            with st.expander(f"Source {i+1} - Score: {score:.3f}"):
                                st.markdown(text)
                    else:
                        st.error(f"Error: {response.status_code}")

                except requests.Timeout:
                    st.warning("‚ö†Ô∏è Timeout (cold start). Please retry in 10s!")
                except Exception as e:
                    st.error(f"Error: {e}")
        else:
            st.warning("Enter a question first!")

    st.markdown("### üí° Sample Questions")

    col1, col2 = st.columns(2)
    samples = [
        "What are the cold chain requirements?",
        "Explain supplier reliability standards",
    ]

    with col1:
        if st.button(samples[0], key="sample1", use_container_width=True):
            st.session_state.question = samples[0]
            st.rerun()

    with col2:
        if st.button(samples[1], key="sample2", use_container_width=True):
            st.session_state.question = samples[1]
            st.rerun()

elif page == "üß† ML Models":
    st.title("üß† Custom ML Models")
    st.markdown("Scikit-learn & PyTorch models for supply chain predictions")

    # Connection status
    try:
        health_response = requests.get(f"{MODEL_INFERENCE_URL}/health", timeout=5)
        if health_response.status_code == 200:
            health_data = health_response.json()
            models_loaded = health_data.get("models_loaded", 0)
            available_models = health_data.get("available_models", [])

            st.markdown(
                f'<div class="success-box">üü¢ Model Inference Service Online - v{health_data.get("version", "2.0")}<br>'  # noqa: E501
                f'<strong>Models Loaded:</strong> {models_loaded} ({", ".join(available_models)})</div>',  # noqa: E501
                unsafe_allow_html=True,
            )
        else:
            st.markdown(
                '<div class="warning-box">‚ö†Ô∏è Model service unreachable</div>',  # noqa: E501
                unsafe_allow_html=True,
            )
    except Exception:
        st.markdown(
            '<div class="warning-box">‚ö†Ô∏è Model service unavailable - Update MODEL_INFERENCE_URL in code</div>',  # noqa: E501
            unsafe_allow_html=True,
        )

    st.markdown("---")

    # Model Info Section
    col1, col2 = st.columns([1, 1])

    with col1:
        st.markdown("### üìä Model Performance")

        # Model selector
        selected_model = st.selectbox(
            "Select Model",
            ["supply_chain_rf", "demand_forecasting_legacy"],
            format_func=lambda x: (
                "Random Forest (Scikit-learn)"
                if x == "supply_chain_rf"
                else "Legacy (NumPy)"
            ),
            key="model_selector",
        )

        try:
            info_response = requests.get(
                f"{MODEL_INFERENCE_URL}/models/{selected_model}/info", timeout=5
            )
            if info_response.status_code == 200:
                model_info = info_response.json()

                # Compact metrics display with smaller font
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    model_type = model_info.get("model_type", "N/A")
                    # Shorten if too long
                    if len(model_type) > 12:
                        model_type = model_type[:10] + "..."
                    st.metric("Type", model_type, label_visibility="visible")
                with col_b:
                    st.metric("Ver", model_info.get("version", "N/A"))
                with col_c:
                    status = "‚úÖ" if model_info.get("trained") else "‚ö†Ô∏è"
                    st.metric("OK", status)

                # Feature importance with WHITE background
                if (
                    "feature_importance" in model_info
                    and model_info["feature_importance"]
                ):
                    st.markdown("#### Feature Importance")
                    importance = model_info["feature_importance"]

                    # Convert to dataframe and sort
                    importance_df = pd.DataFrame(
                        [
                            {"Feature": k.replace("_", " ").title(), "Importance": v}
                            for k, v in importance.items()
                        ]
                    ).sort_values("Importance", ascending=False)

                    # Create chart with WHITE background and BLACK text
                    import plotly.graph_objects as go

                    fig = go.Figure(
                        data=[
                            go.Bar(
                                x=importance_df["Importance"],
                                y=importance_df["Feature"],
                                orientation="h",
                                marker={
                                    "color": "#0d6efd",
                                    "line": {"color": "#0a58ca", "width": 1},
                                },
                            )
                        ]
                    )

                    fig.update_layout(
                        plot_bgcolor="white",
                        paper_bgcolor="white",
                        font={
                            "color": "#212529",
                            "size": 13,
                            "family": "Arial, sans-serif",
                        },
                        xaxis={
                            "title": "Importance",
                            "title_font": {
                                "color": "#212529",
                                "size": 14,
                                "family": "Arial",
                            },
                            "gridcolor": "#dee2e6",
                            "showline": True,
                            "linewidth": 1.5,
                            "linecolor": "#212529",
                            "tickfont": {"color": "#212529", "size": 12},
                            "zerolinecolor": "#495057",
                            "zerolinewidth": 1.5,
                        },
                        yaxis={
                            "title": "",
                            "showline": True,
                            "linewidth": 1.5,
                            "linecolor": "#212529",
                            "tickfont": {"color": "#212529", "size": 12},
                        },
                        margin={"l": 160, "r": 20, "t": 30, "b": 50},
                        height=340,
                    )

                    st.plotly_chart(fig, use_container_width=True)

                    # Top 3 features
                    st.markdown("**Top 3 Predictors:**")
                    for row in importance_df.head(3).itertuples(index=False, name=None):
                        st.markdown(f"- **{row[0]}**: {row[1]:.3f}")

                # MLflow integration info - wider box
                if model_info.get("mlflow_run_id"):
                    st.markdown("---")
                    st.markdown("**MLflow Integration:**")
                    run_id = model_info["mlflow_run_id"]
                    st.markdown(
                        f'<div style="background-color: #f8f9fa; padding: 12px; border-radius: 5px; border-left: 4px solid #0d6efd; word-wrap: break-word;">'  # noqa: E501
                        f'<p style="margin: 0; color: #212529; font-size: 12px; font-family: monospace;"><strong>Run ID:</strong><br>{run_id}</p>'  # noqa: E501
                        f"</div>",
                        unsafe_allow_html=True,
                    )
                    if model_info.get("mlflow_model_uri"):
                        uri = model_info["mlflow_model_uri"]
                        st.markdown(
                            f'<p style="color: #6c757d; font-size: 11px; margin-top: 8px; word-wrap: break-word; font-family: monospace;">üì¶ {uri}</p>',  # noqa: E501
                            unsafe_allow_html=True,
                        )
            else:
                # Fallback if service unavailable
                col_a, col_b, col_c = st.columns(3)
                with col_a:
                    st.metric("Model Type", "Random Forest")
                with col_b:
                    st.metric("Version", "2.0.0")
                with col_c:
                    st.metric("MAE", "~2.5 hrs")
                st.info("Connect to live service to see detailed metrics")

        except Exception as e:
            st.warning(f"Could not load model info: {str(e)}")
            # Show static metrics as fallback
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("Model Type", "Random Forest")
            with col_b:
                st.metric("Version", "2.0.0")
            with col_c:
                st.metric("MAE", "~2.5 hrs")

    with col2:
        st.markdown("### üß™ Live Prediction Demo")

        # Enhanced CSS for form elements - force white backgrounds everywhere
        st.markdown(
            """
        <style>
        /* Selectbox styling - white background, black text */
        div[data-baseweb="select"] > div {
            background-color: white !important;
        }
        div[data-baseweb="select"] span {
            color: black !important;
        }

        /* Dropdown menu items */
        [role="listbox"] {
            background-color: white !important;
        }
        [role="option"] {
            background-color: white !important;
            color: black !important;
        }
        [role="option"]:hover {
            background-color: #f8f9fa !important;
            color: black !important;
        }

        /* Number input buttons (+ and -) */
        button[kind="stepUp"], button[kind="stepDown"] {
            background-color: white !important;
            color: black !important;
            border: 1px solid #dee2e6 !important;
        }
        button[kind="stepUp"]:hover, button[kind="stepDown"]:hover {
            background-color: #f8f9fa !important;
        }

        /* Number input field */
        input[type="number"] {
            background-color: white !important;
            color: black !important;
        }

        /* Slider */
        div[data-testid="stSlider"] label {
            color: black !important;
        }
        </style>
        """,
            unsafe_allow_html=True,
        )

        # Input form
        with st.form("prediction_form"):
            category = st.selectbox(
                "Product Category",
                ["Dairy", "Produce", "Meat", "Bakery", "Frozen"],
                key="category",
            )

            col_x, col_y = st.columns(2)
            with col_x:
                quantity = st.number_input(
                    "Order Quantity", 10, 1000, 500, step=50, key="qty"
                )
                distance = st.number_input(
                    "Distance (miles)", 5, 500, 150, step=10, key="dist"
                )
                reliability = st.slider("Supplier Reliability", 60, 100, 85, key="rel")

            with col_y:
                day = st.selectbox(
                    "Day of Week",
                    list(range(7)),
                    format_func=lambda x: [
                        "Mon",
                        "Tue",
                        "Wed",
                        "Thu",
                        "Fri",
                        "Sat",
                        "Sun",
                    ][x],
                    key="day",
                )
                season = st.selectbox(
                    "Season",
                    list(range(4)),
                    format_func=lambda x: ["Winter", "Spring", "Summer", "Fall"][x],
                    key="season",
                )
                weather = st.selectbox(
                    "Weather",
                    [0, 1, 2],
                    format_func=lambda x: ["Clear", "Rain", "Snow"][x],
                    key="weather",
                )

            submitted = st.form_submit_button(
                "üîÆ Predict Fulfillment Time", type="primary", use_container_width=True
            )

        if submitted:
            with st.spinner("Making prediction..."):
                try:
                    # Map category to index
                    category_map = {
                        "Dairy": 0,
                        "Produce": 1,
                        "Meat": 2,
                        "Bakery": 3,
                        "Frozen": 4,
                    }

                    payload = {
                        "product_category": category_map[category],
                        "order_quantity": int(quantity),
                        "warehouse_distance": float(distance),
                        "day_of_week": int(day),
                        "season": int(season),
                        "supplier_reliability": float(reliability),
                        "weather_condition": int(weather),
                    }

                    # Debug: show payload
                    with st.expander("üîç Debug: Request Payload"):
                        st.json(payload)

                    pred_response = requests.post(
                        f"{MODEL_INFERENCE_URL}/predict/demand",
                        json=payload,
                        timeout=30,
                    )

                    if pred_response.status_code == 200:
                        result = pred_response.json()
                        hours = result["predicted_fulfillment_hours"]

                        st.markdown("### ‚úÖ Prediction Result")
                        st.markdown(
                            f'<div class="success-box">'
                            f'<h2 style="margin:0; color: #155724;">‚è±Ô∏è {hours:.1f} hours</h2>'  # noqa: E501
                            f'<p style="margin:5px 0 0 0; color: #155724;">Expected fulfillment time for this order</p>'  # noqa: E501
                            f"</div>",
                            unsafe_allow_html=True,
                        )

                        # Additional context
                        if hours < 12:
                            st.info("üöÄ Fast delivery expected!")
                        elif hours < 24:
                            st.info("üì¶ Standard delivery timeline")
                        else:
                            st.warning("‚è∞ Extended delivery time")

                        # Show model info
                        with st.expander("üìã Prediction Details"):
                            st.json(result)

                    else:
                        st.error(f"Prediction failed: {pred_response.status_code}")
                        st.code(pred_response.text)

                except requests.Timeout:
                    st.warning(
                        "‚ö†Ô∏è Request timeout. Service may be cold-starting (first request takes 60-90s)."  # noqa: E501
                    )
                except Exception as e:
                    st.error(f"Error: {str(e)}")
                    st.info(
                        "üí° Make sure MODEL_INFERENCE_URL is set correctly in the code"
                    )

    st.markdown("---")

    # Model Management Section
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("### üìö Available Models")

        try:
            models_response = requests.get(f"{MODEL_INFERENCE_URL}/models", timeout=5)
            if models_response.status_code == 200:
                models_data = models_response.json()
                models_list = models_data.get("models", {})

                for model_name, metadata in models_list.items():
                    with st.expander(
                        f"**{model_name}** - {metadata.get('description', 'No description')}"  # noqa: E501
                    ):
                        col_m1, col_m2, col_m3 = st.columns(3)
                        with col_m1:
                            st.metric("Framework", metadata.get("framework", "N/A"))
                        with col_m2:
                            st.metric("Version", metadata.get("version", "N/A"))
                        with col_m3:
                            st.metric("Status", metadata.get("status", "N/A"))

                        if metadata.get("mlflow_integrated"):
                            st.caption("‚úÖ MLflow Tracking Enabled")
            else:
                # Fallback table with white background
                models_data = pd.DataFrame(
                    {
                        "Model": ["Random Forest", "Legacy Numpy"],
                        "Type": ["Scikit-learn", "NumPy"],
                        "Status": ["‚úÖ Active", "‚úÖ Active"],
                        "Version": ["2.0.0", "1.0.0"],
                        "MLflow": ["Yes", "No"],
                    }
                )
                st.dataframe(models_data, use_container_width=True, hide_index=True)

        except Exception as e:
            st.warning(f"Could not fetch model list: {e}")

    with col2:
        st.markdown("### ‚öôÔ∏è Model Actions")

        if st.button("üîÑ Reload All Models", use_container_width=True, key="reload"):
            with st.spinner("Reloading models..."):
                try:
                    reload_response = requests.post(
                        f"{MODEL_INFERENCE_URL}/reload", timeout=30
                    )
                    if reload_response.status_code == 200:
                        st.success("‚úÖ Models reloaded successfully!")
                        st.rerun()
                    else:
                        st.error(f"Reload failed: {reload_response.status_code}")
                except Exception as e:
                    st.error(f"Error: {e}")

        st.markdown("---")

        if st.button("üöÄ Train New Model", use_container_width=True, key="train"):
            with st.spinner("Starting training... (this may take 30-60s)"):
                try:
                    train_payload = {
                        "model_name": "supply_chain_rf",
                        "n_estimators": 100,
                        "max_depth": 10,
                        "log_to_mlflow": True,
                    }
                    train_response = requests.post(
                        f"{MODEL_INFERENCE_URL}/train/supply_chain_rf",
                        json=train_payload,
                        timeout=120,
                    )
                    if train_response.status_code == 200:
                        st.success(
                            "‚úÖ Training started in background! Check logs for progress."  # noqa: E501
                        )
                    else:
                        st.error(f"Training failed: {train_response.status_code}")
                except requests.Timeout:
                    st.info(
                        "‚è≥ Training started but response timed out. Check service logs."  # noqa: E501
                    )
                except Exception as e:
                    st.error(f"Error: {e}")

    st.markdown("---")

    # Use Case Documentation
    st.markdown("### üéØ Model Use Case")
    st.markdown(
        """
        **Supply Chain Fulfillment Time Prediction Model**

        This Random Forest model predicts order fulfillment time based on:

        - **Product Category**: Different categories have different handling requirements
          - Dairy (0): Fast, temperature-sensitive
          - Produce (1): Fast, freshness-critical
          - Meat (2): Moderate, quality checks
          - Bakery (3): Fast, daily batches
          - Frozen (4): Slower, special handling

        - **Order Quantity**: Larger orders take longer to pick/pack
        - **Warehouse Distance**: Shipping time increases with distance
        - **Day of Week**: Weekends and Mondays have different patterns
        - **Season**: Seasonal demand affects fulfillment speed
        - **Supplier Reliability**: Higher reliability = faster fulfillment
        - **Weather Conditions**: Clear/Rain/Snow affect delivery speed

        **Business Value:**
        - Set accurate customer expectations
        - Optimize inventory placement
        - Identify potential delays early
        - Improve supplier performance management
        """  # noqa: E501
    )

    # Links
    st.markdown("---")
    col_a, col_b, col_c = st.columns(3)
    with col_a:
        st.link_button("Open MLflow Dashboard", MLFLOW_UI_URL), use_container_width=True)
    with col_b:
        st.link_button(
            "üìñ Model API Docs", f"{MODEL_INFERENCE_UI_URL}/docs", use_container_width=True
        )
    with col_c:
        if st.button("üîÑ Refresh Page", use_container_width=True, key="refresh"):
            st.rerun()

elif page == "üß™ MLflow":
    st.title("üß™ MLflow Experiment Tracking")
    st.markdown("Model versioning and experiment management")

    # MLflow status
    try:
        mlflow_health = requests.get(f"{MLFLOW_TRACKING_URI}/health", timeout=5)
        if mlflow_health.status_code == 200:
            st.markdown(
                '<div class="success-box">üü¢ MLflow Connected</div>',
                unsafe_allow_html=True,
            )
        else:
            st.error("‚ùå MLflow Unavailable")
    except Exception as e:
        st.error(f"‚ùå Cannot reach MLflow: {str(e)}")

    st.markdown("---")

    # Quick stats
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Experiments", "3", "+0")
    with col2:
        st.metric("Total Runs", "150+", "+50 today")
    with col3:
        st.metric("Models", "3", "Active")
    with col4:
        st.metric("Backend", "PostgreSQL", "‚úÖ")

    st.markdown("---")

    # Experiment info
    st.markdown("### üìä Active Experiments")

    experiments = pd.DataFrame(
        {
            "Experiment": [
                "supply-chain.orders",
                "supply-chain.predictions",
                "supply-chain.alerts",
            ],
            "Runs": ["50+", "50+", "5+"],
            "Description": [
                "Order intake and validation tracking",
                "ML model predictions and performance",
                "High-risk alerts and interventions",
            ],
            "Status": ["üü¢ Active", "üü¢ Active", "üü¢ Active"],
        }
    )

    st.dataframe(experiments, use_container_width=True, hide_index=True)

    st.markdown("---")

    # MLflow UI link
    st.markdown("### üîó MLflow UI")
    st.markdown(
        """
    Click below to open the full MLflow UI to:
    - View experiment runs in detail
    - Compare model performance
    - Inspect parameters and metrics
    - Download model artifacts
    """
    )

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.link_button(
            "üöÄ Open MLflow Dashboard",
            MLFLOW_TRACKING_URI,
            use_container_width=True,
            type="primary",
        )

    st.markdown("---")

    # Recent activity
    st.markdown("### üïê Recent Runs")
    recent_runs = pd.DataFrame(
        {
            "Experiment": [
                "predictions",
                "predictions",
                "orders",
                "alerts",
                "predictions",
            ],
            "Run ID": ["abc123...", "def456...", "ghi789...", "jkl012...", "mno345..."],
            "Status": ["‚úÖ Finished"] * 5,
            "Duration": ["1.2s", "0.9s", "0.5s", "1.8s", "1.1s"],
            "Time": ["2 min ago", "3 min ago", "5 min ago", "7 min ago", "9 min ago"],
        }
    )

    st.dataframe(recent_runs, use_container_width=True, hide_index=True)

else:  # Health
    st.title("‚ù§Ô∏è System Health")
    st.markdown("All platform components")

    st.markdown(
        '<div class="success-box">üü¢ All Systems Operational</div>',
        unsafe_allow_html=True,
    )

    st.markdown("---")

    services = [
        {"name": "Kafka (GKE)", "latency": "2ms", "uptime": "99.9%"},
        {"name": "ML Consumer", "latency": "0.8ms", "uptime": "100%"},
        {"name": "MLflow", "latency": "45ms", "uptime": "99.8%"},
        {"name": "Cloud SQL", "latency": "8ms", "uptime": "100%"},
        {"name": "RAG Service", "latency": "120ms", "uptime": "99.5%"},
        {"name": "Redis", "latency": "3ms", "uptime": "100%"},
        {"name": "Model Inference", "latency": "10ms", "uptime": "99.9%"},
    ]

    for svc in services:
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.markdown(f"### üü¢ {svc['name']}")
        with col2:
            st.metric("Latency", svc["latency"])
        with col3:
            st.metric("Uptime", svc["uptime"])
        st.markdown("---")

    st.markdown("### üí∞ Cost")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Today", "$3.00", "-$0.20")
    with col2:
        st.metric("This Month", "$95", "+$3.00")
    with col3:
        st.metric("Projected", "$120/mo", "-$30")

st.markdown("---")
st.markdown(
    """
<div style='text-align: center; color: #495057; padding: 20px;'>
    <p style='color: #000000;'>
        <strong>AI Incubator Platform</strong> | Built in 4 days | GenAI + Custom ML | 100% IaC
    </p>
</div>
""",  # noqa: E501
    unsafe_allow_html=True,
)

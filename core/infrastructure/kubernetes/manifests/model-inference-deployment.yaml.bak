# Model Inference Deployment -
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ml-models-pvc
spec:
  accessModes:
    - ReadWriteOnce  # Changed from ReadWriteMany (standard-rwo doesn't support RWX)
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard-rwo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-inference
  labels:
    app: model-inference
spec:
  replicas: 1  # Start with 1, HPA will scale up
  selector:
    matchLabels:
      app: model-inference
  template:
    metadata:
      labels:
        app: model-inference
    spec:
      # Init container to ensure model directory exists
      initContainers:
      - name: init-models
        image: busybox:1.36
        command: ['sh', '-c']
        args:
        - |
          mkdir -p /app/models
          chmod -R 777 /app/models
          echo "Model directory initialized"
        volumeMounts:
        - name: model-storage
          mountPath: /app/models

      containers:
      - name: inference
        image: us-central1-docker.pkg.dev/gen-lang-client-0282248851/ai-platform-repo/model-inference:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8001
          name: http
          protocol: TCP

        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow.default.svc.cluster.local:5000"  # Internal K8s service
        - name: PORT
          value: "8001"
        - name: PYTHONUNBUFFERED
          value: "1"

        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"

        # Health checks with longer startup time for model loading
        livenessProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 60  # Allow time for model training
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3

        readinessProbe:
          httpGet:
            path: /health
            port: 8001
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3

        volumeMounts:
        - name: model-storage
          mountPath: /app/models
          readOnly: false

      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: ml-models-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: model-inference
  labels:
    app: model-inference
spec:
  type: LoadBalancer
  selector:
    app: model-inference
  ports:
  - port: 80
    targetPort: 8001
    protocol: TCP
    name: http
  sessionAffinity: ClientIP  # Sticky sessions for better performance
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: model-inference-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: model-inference
  minReplicas: 1  # Start with 1 to save costs
  maxReplicas: 5  # Reduced from 10 for cost efficiency
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60
